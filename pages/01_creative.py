import streamlit as st
import random
import requests
import base64
from openai import OpenAI

# ================== é¡µé¢é…ç½® ==================
st.set_page_config(layout="wide", page_title="Creative Engine")

# ================== OpenAI / DeepSeek ==================
client = OpenAI(
    api_key=st.secrets["DEEPSEEK_KEY"],
    base_url="https://api.deepseek.com"
)

# ================== GitHub ä»“åº“é…ç½®ï¼ˆä»…åå°ï¼‰ ==================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO = "losran/tattoo-ai-tool"

WAREHOUSE = {
    "Subject": "data/subjects.txt",
    "Action": "data/actions.txt",
    "Mood": "data/moods.txt",
    "Usage": "data/usage.txt",
    "StyleSystem": "data/styles_system.txt",
    "Technique": "data/styles_technique.txt",
    "Color": "data/styles_color.txt",
    "Texture": "data/styles_texture.txt",
    "Composition": "data/styles_composition.txt",
    "Accent": "data/styles_accent.txt"
}

# ================== Session State ==================
if "generated_cache" not in st.session_state:
    st.session_state.generated_cache = []

if "selected_prompts" not in st.session_state:
    st.session_state.selected_prompts = []

if "polished_text" not in st.session_state:
    st.session_state.polished_text = ""

# ================== å·¥å…·å‡½æ•° ==================
def get_github_data(path):
    url = f"https://api.github.com/repos/{REPO}/contents/{path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    resp = requests.get(url, headers=headers, timeout=10)
    if resp.status_code == 200:
        content = base64.b64decode(resp.json()["content"]).decode()
        return [l.strip() for l in content.splitlines() if l.strip()]
    return []


def chaos_pick(chaos, low, mid, high):
    if chaos < 30:
        return random.randint(*low)
    elif chaos < 70:
        return random.randint(*mid)
    else:
        return random.randint(*high)


def smart_sample_with_ai(category, user_intent, inventory, chaos_val):
    """
    - åªå…è®¸ä»ä»“åº“ inventory ä¸­å–è¯
    - AI ä¸å¾—é€ è¯
    """
    if not inventory:
        return []

    shuffled_pool = random.sample(inventory, min(len(inventory), 40))
    temp = chaos_val / 100.0

    if not user_intent.strip():
        return random.sample(shuffled_pool, min(2, len(shuffled_pool)))

    if chaos_val < 20:
        guide = "æŒ‘é€‰æœ€ç¨³å®šã€æœ€åè°ƒçš„è¯"
    elif chaos_val < 60:
        guide = "æŒ‘é€‰å…·æœ‰å¼ åŠ›ä½†ä¸çªå…€çš„è¯"
    else:
        guide = "æŒ‘é€‰åå·®æœ€å¤§ã€æœ€å†·é—¨çš„è¯"

    prompt = f"""
    åˆ†ç±»ï¼š{category}
    è¯åº“ï¼š{shuffled_pool}

    è§„åˆ™ï¼š
    1. åªèƒ½ä»è¯åº“ä¸­é€‰æ‹©ï¼Œä¸å¾—æ–°å¢è¯è¯­
    2. {guide}
    3. è¿”å› 1-2 ä¸ªè¯
    4. åªè¾“å‡ºè¯è¯­ï¼Œç”¨é€—å·åˆ†éš”
    """

    try:
        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=temp
        )
        raw = res.choices[0].message.content
        words = [w.strip() for w in raw.replace("ï¼Œ", ",").split(",") if w.strip()]
        valid = [w for w in words if w in shuffled_pool]
        return valid if valid else random.sample(shuffled_pool, 1)
    except Exception:
        return random.sample(shuffled_pool, 1)


# ================== UI ==================
st.title("ğŸ¨ Creative Engine")

chaos_level = st.slider("æ··ä¹±åº¦", 0, 100, 55)
num = st.number_input("ç”Ÿæˆæ•°é‡", 1, 10, 6)
intent_input = st.text_area("åˆ›ä½œæ„å›¾", placeholder="ä¾‹å¦‚ï¼šé’è›™ / æ—¥å¼ / emo")

if st.button("ğŸ”¥ æ¿€å‘ç»„åˆ", type="primary", use_container_width=True):
    st.session_state.polished_text = ""
    st.session_state.selected_prompts = []

    # ğŸ‘‰ åå°è¯»å–çœŸå®ä»“åº“
    db = {k: get_github_data(v) for k, v in WAREHOUSE.items()}

    new_batch = []

    subjects = smart_sample_with_ai("ä¸»ä½“", intent_input, db["Subject"], chaos_level)
    actions  = smart_sample_with_ai("åŠ¨ä½œ", intent_input, db["Action"], chaos_level)
    moods    = smart_sample_with_ai("æƒ…ç»ª", intent_input, db["Mood"], chaos_level)
    usages   = smart_sample_with_ai("éƒ¨ä½", intent_input, db["Usage"], chaos_level)

    stylesys = smart_sample_with_ai("ç³»ç»Ÿ", intent_input, db["StyleSystem"], chaos_level)
    tech     = smart_sample_with_ai("æŠ€æ³•", intent_input, db["Technique"], chaos_level)
    color    = smart_sample_with_ai("è‰²å½©", intent_input, db["Color"], chaos_level)
    texture  = smart_sample_with_ai("è‚Œç†", intent_input, db["Texture"], chaos_level)
    comp     = smart_sample_with_ai("æ„å›¾", intent_input, db["Composition"], chaos_level)
    accent   = smart_sample_with_ai("ç‚¹ç¼€", intent_input, db["Accent"], chaos_level)

    for _ in range(num):
        new_batch.append(
            f"{random.choice(subjects)}ï¼Œ"
            f"{random.choice(stylesys)}ï¼Œ{random.choice(tech)}ï¼Œ{random.choice(color)}ï¼Œ"
            f"{random.choice(texture)}ï¼Œ{random.choice(comp)}ï¼Œ"
            f"{random.choice(actions)}ï¼Œ{random.choice(moods)}ï¼Œ"
            + (f"{random.choice(accent)}ï¼Œ" if accent and chaos_level > 60 else "")
            + f"çº¹åœ¨{random.choice(usages)}"
        )

    st.session_state.generated_cache = new_batch
    st.rerun()


# ================== æ–¹æ¡ˆé€‰æ‹© ==================
if st.session_state.generated_cache:
    st.divider()
    st.subheader("ğŸ² æ–¹æ¡ˆé€‰æ‹©")

    cols = st.columns(2)
    for i, p in enumerate(st.session_state.generated_cache):
        with cols[i % 2]:
            sel = p in st.session_state.selected_prompts
            if st.button(p, key=f"pick_{i}", type="primary" if sel else "secondary", use_container_width=True):
                if sel:
                    st.session_state.selected_prompts.remove(p)
                else:
                    st.session_state.selected_prompts.append(p)
                st.rerun()


# ================== æ¶¦è‰² ==================
if st.session_state.selected_prompts and not st.session_state.polished_text:
    st.divider()
    if st.button("âœ¨ å¼€å§‹æ¶¦è‰²", type="primary", use_container_width=True):
        with st.spinner("AI æ­£åœ¨æ¶¦è‰²..."):
            text = "\n".join([f"æ–¹æ¡ˆ{i+1}ï¼š{p}" for i, p in enumerate(st.session_state.selected_prompts)])

            sys_prompt = """
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçº¹èº«è®¾è®¡è¯´æ˜æ’°å†™è€…ã€‚
            è¯·å°†ä»¥ä¸‹æ–¹æ¡ˆæ¶¦è‰²ä¸ºå¯ç›´æ¥ç”¨äºåˆºé’è®¾è®¡æ²Ÿé€šçš„ä¸­æ–‡æè¿°ã€‚
            è¦æ±‚ï¼š
            - æ¯æ¡ä¸å°‘äº 60 å­—
            - å¿…é¡»å‡ºç°â€œçº¹èº«â€
            - ç¦æ­¢æŠ’æƒ…ä¸æ–‡å­¦åŒ–
            - æ ¼å¼å¿…é¡»ä¸º **æ–¹æ¡ˆXï¼š**
            """

            res = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=0.7
            )

            st.session_state.polished_text = res.choices[0].message.content
            st.rerun()


# ================== æœ€ç»ˆè¾“å‡º ==================
if st.session_state.polished_text:
    st.divider()
    st.subheader("ğŸ¨ æ¶¦è‰²å®Œæˆ")
    st.text_area("æœ€ç»ˆæ–‡æ¡ˆ", st.session_state.polished_text, height=420)

    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸš€ å‘é€åˆ°è‡ªåŠ¨åŒ–", use_container_width=True):
            st.session_state.auto_input_cache = st.session_state.polished_text
            st.switch_page("pages/02_automation.py")
    with c2:
        if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
            st.session_state.generated_cache = []
            st.session_state.selected_prompts = []
            st.session_state.polished_text = ""
            st.rerun()
